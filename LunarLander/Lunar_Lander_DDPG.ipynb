{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this file to load the actor critic (or train a new one) and create or enlarge a dataset of successful movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "th.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Ornstein-Uhlenbeck Noise for exploration\n",
    "class OUNoise:\n",
    "    def __init__(self, action_dim, mu=0.0, theta=0.15, sigma=0.2):\n",
    "        self.action_dim = action_dim\n",
    "        self.mu = mu * np.ones(action_dim)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.state = np.copy(self.mu)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.copy(self.mu)\n",
    "    \n",
    "    def sample(self):\n",
    "        dx = self.theta * (self.mu - self.state) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state += dx\n",
    "        return self.state\n",
    "\n",
    "# Custom Reward Wrapper\n",
    "class HoverLunarLander(gym.Wrapper):\n",
    "    def __init__(self, env, target_location=(0.1, 0.25), epsilon=1e-3, \n",
    "                 penalty_landing=-50.0, penalty_crashing=-100.0, penalty_offscreen=-100.0):\n",
    "        super(HoverLunarLander, self).__init__(env)\n",
    "        self.target_x = target_location[0]\n",
    "        self.target_y = target_location[1]\n",
    "        self.epsilon = epsilon\n",
    "        self.penalty_landing = penalty_landing\n",
    "        self.penalty_crashing = penalty_crashing\n",
    "        self.penalty_offscreen = penalty_offscreen\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take a step in the original environment\n",
    "        state, original_reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        # Extract position from state (state[0]: x, state[1]: y)\n",
    "        x, y = state[0], state[1]\n",
    "        \n",
    "        # Compute distance to target location\n",
    "        distance = math.sqrt((x - self.target_x)**2 + (y - self.target_y)**2)\n",
    "        \n",
    "        # Compute inverse distance reward\n",
    "        inverse_distance_reward = 1.0 / (distance + self.epsilon)\n",
    "        \n",
    "        # Initialize new reward\n",
    "        new_reward = inverse_distance_reward\n",
    "        \n",
    "        # Check for penalties\n",
    "        if terminated:\n",
    "            # Determine if landed successfully\n",
    "            if self.is_landed(state):\n",
    "                new_reward += self.penalty_landing\n",
    "                info['termination_cause'] = 'landed'\n",
    "            else:\n",
    "                new_reward += self.penalty_crashing\n",
    "                info['termination_cause'] = 'crashed'\n",
    "        elif truncated:\n",
    "            # Went off-screen\n",
    "            new_reward += self.penalty_offscreen\n",
    "            info['termination_cause'] = 'offscreen'\n",
    "        \n",
    "        return state, new_reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "    \n",
    "    def is_landed(self, state):\n",
    "        # Criteria for successful landing:\n",
    "        # 1. Both legs are in contact (state[6] and state[7] == 1)\n",
    "        # 2. Vertical and horizontal velocities are low\n",
    "        # 3. Angle is near vertical\n",
    "        leg_contact = state[6] == 1 and state[7] == 1\n",
    "        vertical_velocity = abs(state[3]) < 0.5  # state[3] is y-velocity\n",
    "        horizontal_velocity = abs(state[2]) < 0.5  # state[2] is x-velocity\n",
    "        angle = abs(state[4]) < 0.1  # state[4] is angle\n",
    "        \n",
    "        return leg_contact and vertical_velocity and horizontal_velocity and angle\n",
    "\n",
    "# Actor Network with Layer Normalization\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.max_action = max_action\n",
    "        \n",
    "        self.layer1 = nn.Linear(state_dim, 400)\n",
    "        self.ln1 = nn.LayerNorm(400)\n",
    "        self.layer2 = nn.Linear(400, 300)\n",
    "        self.ln2 = nn.LayerNorm(300)\n",
    "        self.layer3 = nn.Linear(300, 200)\n",
    "        self.ln3 = nn.LayerNorm(200)\n",
    "        self.layer4 = nn.Linear(200, action_dim)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.output_activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = self.activation(self.ln1(self.layer1(state)))\n",
    "        x = self.activation(self.ln2(self.layer2(x)))\n",
    "        x = self.activation(self.ln3(self.layer3(x)))\n",
    "        x = self.output_activation(self.layer4(x))\n",
    "        return x * self.max_action\n",
    "\n",
    "# Critic Network with Layer Normalization\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.ln1 = nn.LayerNorm(400)\n",
    "        self.layer2 = nn.Linear(400, 300)\n",
    "        self.ln2 = nn.LayerNorm(300)\n",
    "        self.layer3 = nn.Linear(300, 200)\n",
    "        self.ln3 = nn.LayerNorm(200)\n",
    "        self.layer4 = nn.Linear(200, 1)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = th.cat([state, action], dim=1)\n",
    "        x = self.activation(self.ln1(self.layer1(x)))\n",
    "        x = self.activation(self.ln2(self.layer2(x)))\n",
    "        x = self.activation(self.ln3(self.layer3(x)))\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "# Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=1000000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# DDPG Agent with Flexible Initialization\n",
    "class DDPGAgent:\n",
    "    def __init__(self, state_dim, action_dim, max_action, device, actor=None, critic=None):\n",
    "        \"\"\"\n",
    "        Initializes the DDPG Agent.\n",
    "        \n",
    "        Args:\n",
    "            state_dim (int): Dimension of the state space.\n",
    "            action_dim (int): Dimension of the action space.\n",
    "            max_action (float): Maximum action value.\n",
    "            device (torch.device): Device to run the networks on.\n",
    "            actor (nn.Module, optional): Preloaded Actor network. Defaults to None.\n",
    "            critic (nn.Module, optional): Preloaded Critic network. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.max_action = max_action\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.005\n",
    "        self.batch_size = 64\n",
    "        self.grad_clip = 1.0  # Gradient clipping value\n",
    "        \n",
    "        # Initialize Actor Network\n",
    "        if actor is not None:\n",
    "            self.actor = actor.to(device)\n",
    "            print(\"Preloaded Actor network loaded.\")\n",
    "        else:\n",
    "            self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "            print(\"New Actor network initialized.\")\n",
    "        \n",
    "        # Initialize Actor Target Network\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        if actor is not None:\n",
    "            self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "            print(\"Actor target network initialized with preloaded Actor weights.\")\n",
    "        else:\n",
    "            self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "            print(\"Actor target network initialized with Actor weights.\")\n",
    "        \n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Initialize Critic Network\n",
    "        if critic is not None:\n",
    "            self.critic = critic.to(device)\n",
    "            print(\"Preloaded Critic network loaded.\")\n",
    "        else:\n",
    "            self.critic = Critic(state_dim, action_dim).to(device)\n",
    "            print(\"New Critic network initialized.\")\n",
    "        \n",
    "        # Initialize Critic Target Network\n",
    "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "        if critic is not None:\n",
    "            self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "            print(\"Critic target network initialized with preloaded Critic weights.\")\n",
    "        else:\n",
    "            self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "            print(\"Critic target network initialized with Critic weights.\")\n",
    "        \n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=1e-3)\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        state = th.FloatTensor(state.reshape(1, -1)).to(self.device)\n",
    "        self.actor.eval()\n",
    "        with th.no_grad():\n",
    "            action = self.actor(state).cpu().data.numpy().flatten()\n",
    "        self.actor.train()\n",
    "        return action\n",
    "    \n",
    "    def train(self, replay_buffer):\n",
    "        if len(replay_buffer) < self.batch_size:\n",
    "            return None, None\n",
    "        \n",
    "        # Sample from replay buffer\n",
    "        state, action, reward, next_state, done = replay_buffer.sample(self.batch_size)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        state = th.FloatTensor(state).to(self.device)\n",
    "        action = th.FloatTensor(action).to(self.device)\n",
    "        reward = th.FloatTensor(reward).reshape(-1, 1).to(self.device)\n",
    "        next_state = th.FloatTensor(next_state).to(self.device)\n",
    "        done = th.FloatTensor(done).reshape(-1, 1).to(self.device)\n",
    "        \n",
    "        # Compute target Q value\n",
    "        with th.no_grad():\n",
    "            target_Q = self.critic_target(next_state, self.actor_target(next_state))\n",
    "            target_Q = reward + (1 - done) * self.gamma * target_Q\n",
    "        \n",
    "        # Get current Q value\n",
    "        current_Q = self.critic(state, action)\n",
    "        \n",
    "        # Compute critic loss\n",
    "        critic_loss = nn.MSELoss()(current_Q, target_Q)\n",
    "        \n",
    "        # Optimize the critic\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        # Gradient clipping\n",
    "        nn.utils.clip_grad_norm_(self.critic.parameters(), self.grad_clip)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Compute actor loss\n",
    "        actor_loss = -self.critic(state, self.actor(state)).mean()\n",
    "        \n",
    "        # Optimize the actor\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        # Gradient clipping\n",
    "        nn.utils.clip_grad_norm_(self.actor.parameters(), self.grad_clip)\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        # Soft update target networks\n",
    "        self.soft_update(self.critic, self.critic_target)\n",
    "        self.soft_update(self.actor, self.actor_target)\n",
    "        \n",
    "        return actor_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def soft_update(self, source, target):\n",
    "        for param, target_param in zip(source.parameters(), target.parameters()):\n",
    "            target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "def train_ddpg(num_episodes=1000, actor=None, critic=None, device=None, \n",
    "              state_dim=None, action_dim=None, max_action=None):\n",
    "    \"\"\"\n",
    "    Trains a DDPG agent on the HoverLunarLander environment.\n",
    "    \n",
    "    Args:\n",
    "        num_episodes (int): Number of training episodes.\n",
    "        actor (nn.Module, optional): Preloaded Actor network. Defaults to None.\n",
    "        critic (nn.Module, optional): Preloaded Critic network. Defaults to None.\n",
    "        device (torch.device, optional): Device to run the networks on. If None, defaults to CUDA if available.\n",
    "        state_dim (int, optional): Dimension of the state space. Required if actor and critic are not provided.\n",
    "        action_dim (int, optional): Dimension of the action space. Required if actor and critic are not provided.\n",
    "        max_action (float, optional): Maximum action value. Required if actor and critic are not provided.\n",
    "    \n",
    "    Returns:\n",
    "        actor (nn.Module): Trained Actor network.\n",
    "        critic (nn.Module): Trained Critic network.\n",
    "        training_logs (dict): Dictionary containing episode rewards and losses.\n",
    "    \"\"\"\n",
    "    # Initialize device\n",
    "    if device is None:\n",
    "        device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize environment to get dimensions if not provided\n",
    "    if state_dim is None or action_dim is None or max_action is None:\n",
    "        temp_env = gym.make(\"LunarLanderContinuous-v2\", render_mode=None)\n",
    "        state_dim = temp_env.observation_space.shape[0]\n",
    "        action_dim = temp_env.action_space.shape[0]\n",
    "        max_action = float(temp_env.action_space.high[0])\n",
    "        temp_env.close()\n",
    "    \n",
    "    # Initialize environment with custom reward\n",
    "    env = HoverLunarLander(gym.make(\"LunarLanderContinuous-v2\", render_mode=None))\n",
    "    \n",
    "    # Initialize agent\n",
    "    agent = DDPGAgent(state_dim, action_dim, max_action, device, actor=actor, critic=critic)\n",
    "    replay_buffer = ReplayBuffer()\n",
    "    \n",
    "    # Initialize exploration noise\n",
    "    exploration_noise = OUNoise(action_dim)\n",
    "    exploration_noise.reset()\n",
    "    \n",
    "    # Initialize training logs\n",
    "    training_logs = {\n",
    "        'episode_rewards': [],\n",
    "        'avg_rewards': [],\n",
    "        'actor_losses': [],\n",
    "        'critic_losses': []\n",
    "    }\n",
    "    \n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        state, _ = env.reset(seed=SEED)\n",
    "        exploration_noise.reset()\n",
    "        episode_reward = 0\n",
    "        actor_loss_ep = 0\n",
    "        critic_loss_ep = 0\n",
    "        steps = 0\n",
    "        \n",
    "        for step in range(1000):  # max_steps\n",
    "            # Select action and add exploration noise\n",
    "            action = agent.select_action(state)\n",
    "            noise = exploration_noise.sample()\n",
    "            action = action + noise\n",
    "            action = np.clip(action, -agent.max_action, agent.max_action)\n",
    "            \n",
    "            # Take action in environment\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            # Store transition in replay buffer\n",
    "            replay_buffer.add(state, action, reward, next_state, float(done))\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "            # Train agent\n",
    "            actor_loss, critic_loss = agent.train(replay_buffer)\n",
    "            if actor_loss is not None and critic_loss is not None:\n",
    "                actor_loss_ep += actor_loss\n",
    "                critic_loss_ep += critic_loss\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        training_logs['episode_rewards'].append(episode_reward)\n",
    "        if actor_loss_ep != 0 and critic_loss_ep != 0:\n",
    "            training_logs['actor_losses'].append(actor_loss_ep / steps)\n",
    "            training_logs['critic_losses'].append(critic_loss_ep / steps)\n",
    "        else:\n",
    "            training_logs['actor_losses'].append(0)\n",
    "            training_logs['critic_losses'].append(0)\n",
    "        \n",
    "        # Logging every 10 episodes\n",
    "        if episode % 10 == 0:\n",
    "            avg_reward = np.mean(training_logs['episode_rewards'][-10:])\n",
    "            avg_actor_loss = np.mean(training_logs['actor_losses'][-10:])\n",
    "            avg_critic_loss = np.mean(training_logs['critic_losses'][-10:])\n",
    "            training_logs['avg_rewards'].append(avg_reward)\n",
    "            print(f\"Episode {episode}\\tAverage Reward: {avg_reward:.2f}\\tAvg Actor Loss: {avg_actor_loss:.4f}\\tAvg Critic Loss: {avg_critic_loss:.4f}\")\n",
    "    \n",
    "    env.close()\n",
    "    return agent.actor, agent.critic, training_logs\n",
    "\n",
    "def render_episode(actor, state_dim, action_dim, max_action, device=None, render_delay=0.02):\n",
    "    \"\"\"\n",
    "    Renders a single episode of the agent interacting with the HoverLunarLander environment.\n",
    "    \n",
    "    Args:\n",
    "        actor (nn.Module): Trained Actor network.\n",
    "        state_dim (int): Dimension of the state space.\n",
    "        action_dim (int): Dimension of the action space.\n",
    "        max_action (float): Maximum action value.\n",
    "        device (torch.device, optional): Device to run the network on. If None, defaults to CUDA if available.\n",
    "        render_delay (float, optional): Delay between frames in seconds. Useful to control rendering speed. Defaults to 0.02.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize device\n",
    "    if device is None:\n",
    "        device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize environment with custom reward\n",
    "    env = HoverLunarLander(gym.make(\"LunarLanderContinuous-v2\", render_mode=\"human\"))\n",
    "    \n",
    "    # Initialize agent with only the actor\n",
    "    agent = DDPGAgent(state_dim, action_dim, max_action, device, actor=actor, critic=None)\n",
    "    \n",
    "    # Initialize environment and get initial state\n",
    "    state, _ = env.reset(seed=SEED)\n",
    "    done = False\n",
    "    step_count = 0\n",
    "    \n",
    "    while not done and step_count < 1000:\n",
    "        action = agent.select_action(state)\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        env.render()\n",
    "        step_count += 1\n",
    "        \n",
    "        # Optional: Add a small delay to make rendering visible\n",
    "        # import time\n",
    "        # time.sleep(render_delay)\n",
    "    \n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train model\n",
    "# actor, critic, training_logs = train_ddpg(num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "state_dim = temp_env.observation_space.shape[0]\n",
    "action_dim = temp_env.action_space.shape[0]\n",
    "max_action = float(temp_env.action_space.high[0])\n",
    "actor = Actor(state_dim, action_dim, max_action)\n",
    "actor.load_state_dict(th.load('actor_custom_reward.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save actor critic, custom reward name\n",
    "\n",
    "# th.save(actor.state_dict(), 'actor_custom_reward.pth')\n",
    "# th.save(critic.state_dict(), 'critic_custom_reward.pth')\n",
    "\n",
    "# #plotting\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.plot(training_logs['episode_rewards'], label='Episode Reward')\n",
    "# plt.plot(training_logs['avg_rewards'], label='Average Reward (10 episodes)')\n",
    "# plt.xlabel('Episode')\n",
    "# plt.ylabel('Reward')\n",
    "# plt.title('DDPG Training on HoverLunarLander')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#render episode\n",
    "#render_episode(actor, state_dim=8, action_dim=2, max_action=1.0, device=None, render_delay=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Get Data With Trained Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most important part of this file for creating or enlarging a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating episode 1...\n",
      "Generating episode 2...\n",
      "Generating episode 3...\n",
      "Generating episode 4...\n",
      "Generating episode 5...\n",
      "Generating episode 6...\n",
      "Generating episode 7...\n",
      "Generating episode 8...\n",
      "Generating episode 9...\n",
      "Generating episode 10...\n",
      "Generating episode 11...\n",
      "Generating episode 12...\n",
      "Generating episode 13...\n",
      "Generating episode 14...\n",
      "Generating episode 15...\n",
      "Generating episode 16...\n",
      "Generating episode 17...\n",
      "Generating episode 18...\n",
      "Generating episode 19...\n",
      "Generating episode 20...\n",
      "Generating episode 21...\n",
      "Generating episode 22...\n",
      "Generating episode 23...\n",
      "Generating episode 24...\n",
      "Generating episode 25...\n",
      "Generating episode 26...\n",
      "Generating episode 27...\n",
      "Generating episode 28...\n",
      "Generating episode 29...\n",
      "Generating episode 30...\n",
      "Generating episode 31...\n",
      "Generating episode 32...\n",
      "Generating episode 33...\n",
      "Generating episode 34...\n",
      "Generating episode 35...\n",
      "Generating episode 36...\n",
      "Generating episode 37...\n",
      "Generating episode 38...\n",
      "Generating episode 39...\n",
      "Generating episode 40...\n",
      "Generating episode 41...\n",
      "Generating episode 42...\n",
      "Generating episode 43...\n",
      "Generating episode 44...\n",
      "Generating episode 45...\n",
      "Generating episode 46...\n",
      "Generating episode 47...\n",
      "Generating episode 48...\n",
      "Generating episode 49...\n",
      "Generating episode 50...\n",
      "Generating episode 51...\n",
      "Generating episode 52...\n",
      "Generating episode 53...\n",
      "Generating episode 54...\n",
      "Generating episode 55...\n",
      "Generating episode 56...\n",
      "Generating episode 57...\n",
      "Generating episode 58...\n",
      "Generating episode 59...\n",
      "Generating episode 60...\n",
      "Generating episode 61...\n",
      "Generating episode 62...\n",
      "Generating episode 63...\n",
      "Generating episode 64...\n",
      "Generating episode 65...\n",
      "Generating episode 66...\n",
      "Generating episode 67...\n",
      "Generating episode 68...\n",
      "Generating episode 69...\n",
      "Generating episode 70...\n",
      "Generating episode 71...\n",
      "Generating episode 72...\n",
      "Generating episode 73...\n",
      "Generating episode 74...\n",
      "Generating episode 75...\n",
      "Generating episode 76...\n",
      "Generating episode 77...\n",
      "Generating episode 78...\n",
      "Generating episode 79...\n",
      "Generating episode 80...\n",
      "Generating episode 81...\n",
      "Generating episode 82...\n",
      "Generating episode 83...\n",
      "Generating episode 84...\n",
      "Generating episode 85...\n",
      "Generating episode 86...\n",
      "Generating episode 87...\n",
      "Generating episode 88...\n",
      "Generating episode 89...\n",
      "Generating episode 90...\n",
      "Generating episode 91...\n",
      "Generating episode 92...\n",
      "Generating episode 93...\n",
      "Generating episode 94...\n",
      "Generating episode 95...\n",
      "Generating episode 96...\n",
      "Generating episode 97...\n",
      "Generating episode 98...\n",
      "Generating episode 99...\n",
      "Generating episode 100...\n",
      "Generating episode 101...\n",
      "Generating episode 102...\n",
      "Generating episode 103...\n",
      "Generating episode 104...\n",
      "Generating episode 105...\n",
      "Generating episode 106...\n",
      "Generating episode 107...\n",
      "Generating episode 108...\n",
      "Generating episode 109...\n",
      "Generating episode 110...\n",
      "Generating episode 111...\n",
      "Generating episode 112...\n",
      "Generating episode 113...\n",
      "Generating episode 114...\n",
      "Generating episode 115...\n",
      "Generating episode 116...\n",
      "Generating episode 117...\n",
      "Generating episode 118...\n",
      "Generating episode 119...\n",
      "Generating episode 120...\n",
      "Generating episode 121...\n",
      "Generating episode 122...\n",
      "Generating episode 123...\n",
      "Generating episode 124...\n",
      "Generating episode 125...\n",
      "Generating episode 126...\n",
      "Generating episode 127...\n",
      "Generating episode 128...\n",
      "Generating episode 129...\n",
      "Generating episode 130...\n",
      "Generating episode 131...\n",
      "Generating episode 132...\n",
      "Generating episode 133...\n",
      "Generating episode 134...\n",
      "Generating episode 135...\n",
      "Generating episode 136...\n",
      "Generating episode 137...\n",
      "Generating episode 138...\n",
      "Generating episode 139...\n",
      "Generating episode 140...\n",
      "Generating episode 141...\n",
      "Generating episode 142...\n",
      "Generating episode 143...\n",
      "Generating episode 144...\n",
      "Generating episode 145...\n",
      "Generating episode 146...\n",
      "Generating episode 147...\n",
      "Generating episode 148...\n",
      "Generating episode 149...\n",
      "Generating episode 150...\n",
      "Generating episode 151...\n",
      "Generating episode 152...\n",
      "Generating episode 153...\n",
      "Generating episode 154...\n",
      "Generating episode 155...\n",
      "Generating episode 156...\n",
      "Generating episode 157...\n",
      "Generating episode 158...\n",
      "Generating episode 159...\n",
      "Generating episode 160...\n",
      "Generating episode 161...\n",
      "Generating episode 162...\n",
      "Generating episode 163...\n",
      "Generating episode 164...\n",
      "Generating episode 165...\n",
      "Generating episode 166...\n",
      "Generating episode 167...\n",
      "Generating episode 168...\n",
      "Generating episode 169...\n",
      "Generating episode 170...\n",
      "Generating episode 171...\n",
      "Generating episode 172...\n",
      "Generating episode 173...\n",
      "Generating episode 174...\n",
      "Generating episode 175...\n",
      "Generating episode 176...\n",
      "Generating episode 177...\n",
      "Generating episode 178...\n",
      "Generating episode 179...\n",
      "Generating episode 180...\n",
      "Generating episode 181...\n",
      "Generating episode 182...\n",
      "Generating episode 183...\n",
      "Generating episode 184...\n",
      "Generating episode 185...\n",
      "Generating episode 186...\n",
      "Generating episode 187...\n",
      "Generating episode 188...\n",
      "Generating episode 189...\n",
      "Generating episode 190...\n",
      "Generating episode 191...\n",
      "Generating episode 192...\n",
      "Generating episode 193...\n",
      "Generating episode 194...\n",
      "Generating episode 195...\n",
      "Generating episode 196...\n",
      "Generating episode 197...\n",
      "Generating episode 198...\n",
      "Generating episode 199...\n",
      "Generating episode 200...\n",
      "Generating episode 201...\n",
      "Generating episode 202...\n",
      "Generating episode 203...\n",
      "Generating episode 204...\n",
      "Generating episode 205...\n",
      "Generating episode 206...\n",
      "Generating episode 207...\n",
      "Generating episode 208...\n",
      "Generating episode 209...\n",
      "Generating episode 210...\n",
      "Generating episode 211...\n",
      "Generating episode 212...\n",
      "Generating episode 213...\n",
      "Generating episode 214...\n",
      "Generating episode 215...\n",
      "Generating episode 216...\n",
      "Generating episode 217...\n",
      "Generating episode 218...\n",
      "Generating episode 219...\n",
      "Generating episode 220...\n",
      "Generating episode 221...\n",
      "Generating episode 222...\n",
      "Generating episode 223...\n",
      "Generating episode 224...\n",
      "Generating episode 225...\n",
      "Generating episode 226...\n",
      "Generating episode 227...\n",
      "Generating episode 228...\n",
      "Generating episode 229...\n",
      "Generating episode 230...\n",
      "Generating episode 231...\n",
      "Generating episode 232...\n",
      "Generating episode 233...\n",
      "Generating episode 234...\n",
      "Generating episode 235...\n",
      "Generating episode 236...\n",
      "Generating episode 237...\n",
      "Generating episode 238...\n",
      "Generating episode 239...\n",
      "Generating episode 240...\n",
      "Generating episode 241...\n",
      "Generating episode 242...\n",
      "Generating episode 243...\n",
      "Generating episode 244...\n",
      "Generating episode 245...\n",
      "Generating episode 246...\n",
      "Generating episode 247...\n",
      "Generating episode 248...\n",
      "Generating episode 249...\n",
      "Generating episode 250...\n",
      "Generating episode 251...\n",
      "Generating episode 252...\n",
      "Generating episode 253...\n",
      "Generating episode 254...\n",
      "Generating episode 255...\n",
      "Generating episode 256...\n",
      "Generating episode 257...\n",
      "Generating episode 258...\n",
      "Generating episode 259...\n",
      "Generating episode 260...\n",
      "Generating episode 261...\n",
      "Generating episode 262...\n",
      "Generating episode 263...\n",
      "Generating episode 264...\n",
      "Generating episode 265...\n",
      "Generating episode 266...\n",
      "Generating episode 267...\n",
      "Generating episode 268...\n",
      "Generating episode 269...\n",
      "Generating episode 270...\n",
      "Generating episode 271...\n",
      "Generating episode 272...\n",
      "Generating episode 273...\n",
      "Generating episode 274...\n",
      "Generating episode 275...\n",
      "Generating episode 276...\n",
      "Generating episode 277...\n",
      "Generating episode 278...\n",
      "Generating episode 279...\n",
      "Generating episode 280...\n",
      "Generating episode 281...\n",
      "Generating episode 282...\n",
      "Generating episode 283...\n",
      "Generating episode 284...\n",
      "Generating episode 285...\n",
      "Generating episode 286...\n",
      "Generating episode 287...\n",
      "Generating episode 288...\n",
      "Generating episode 289...\n",
      "Generating episode 290...\n",
      "Generating episode 291...\n",
      "Generating episode 292...\n",
      "Generating episode 293...\n",
      "Generating episode 294...\n",
      "Generating episode 295...\n",
      "Generating episode 296...\n",
      "Generating episode 297...\n",
      "Generating episode 298...\n",
      "Generating episode 299...\n",
      "Generating episode 300...\n",
      "Generating episode 301...\n",
      "Generating episode 302...\n",
      "Generating episode 303...\n",
      "Generating episode 304...\n",
      "Generating episode 305...\n",
      "Generating episode 306...\n",
      "Generating episode 307...\n",
      "Generating episode 308...\n",
      "Generating episode 309...\n",
      "Generating episode 310...\n",
      "Generating episode 311...\n",
      "Generating episode 312...\n",
      "Generating episode 313...\n",
      "Generating episode 314...\n",
      "Generating episode 315...\n",
      "Generating episode 316...\n",
      "Generating episode 317...\n",
      "Generating episode 318...\n",
      "Generating episode 319...\n",
      "Generating episode 320...\n",
      "Generating episode 321...\n",
      "Generating episode 322...\n",
      "Generating episode 323...\n",
      "Generating episode 324...\n",
      "Generating episode 325...\n",
      "Generating episode 326...\n",
      "Generating episode 327...\n",
      "Generating episode 328...\n",
      "Generating episode 329...\n",
      "Generating episode 330...\n",
      "Generating episode 331...\n",
      "Generating episode 332...\n",
      "Generating episode 333...\n",
      "Generating episode 334...\n",
      "Generating episode 335...\n",
      "Generating episode 336...\n",
      "Generating episode 337...\n",
      "Generating episode 338...\n",
      "Generating episode 339...\n",
      "Generating episode 340...\n",
      "Generating episode 341...\n",
      "Generating episode 342...\n",
      "Generating episode 343...\n",
      "Generating episode 344...\n",
      "Generating episode 345...\n",
      "Generating episode 346...\n",
      "Generating episode 347...\n",
      "Generating episode 348...\n",
      "Generating episode 349...\n",
      "Generating episode 350...\n",
      "Generating episode 351...\n",
      "Generating episode 352...\n",
      "Generating episode 353...\n",
      "Generating episode 354...\n",
      "Generating episode 355...\n",
      "Generating episode 356...\n",
      "Generating episode 357...\n",
      "Generating episode 358...\n",
      "Generating episode 359...\n",
      "Generating episode 360...\n",
      "Generating episode 361...\n",
      "Generating episode 362...\n",
      "Generating episode 363...\n",
      "Generating episode 364...\n",
      "Generating episode 365...\n",
      "Generating episode 366...\n",
      "Generating episode 367...\n",
      "Generating episode 368...\n",
      "Generating episode 369...\n",
      "Generating episode 370...\n",
      "Generating episode 371...\n",
      "Generating episode 372...\n",
      "Generating episode 373...\n",
      "Generating episode 374...\n",
      "Generating episode 375...\n",
      "Generating episode 376...\n",
      "Generating episode 377...\n",
      "Generating episode 378...\n",
      "Generating episode 379...\n",
      "Generating episode 380...\n",
      "Generating episode 381...\n",
      "Generating episode 382...\n",
      "Generating episode 383...\n",
      "Generating episode 384...\n",
      "Generating episode 385...\n",
      "Generating episode 386...\n",
      "Generating episode 387...\n",
      "Generating episode 388...\n",
      "Generating episode 389...\n",
      "Generating episode 390...\n",
      "Generating episode 391...\n",
      "Generating episode 392...\n",
      "Generating episode 393...\n",
      "Generating episode 394...\n",
      "Generating episode 395...\n",
      "Generating episode 396...\n",
      "Generating episode 397...\n",
      "Generating episode 398...\n",
      "Generating episode 399...\n",
      "Generating episode 400...\n",
      "Generating episode 401...\n",
      "Generating episode 402...\n",
      "Generating episode 403...\n",
      "Generating episode 404...\n",
      "Generating episode 405...\n",
      "Generating episode 406...\n",
      "Generating episode 407...\n",
      "Generating episode 408...\n",
      "Generating episode 409...\n",
      "Generating episode 410...\n",
      "Generating episode 411...\n",
      "Generating episode 412...\n",
      "Generating episode 413...\n",
      "Generating episode 414...\n",
      "Generating episode 415...\n",
      "Generating episode 416...\n",
      "Generating episode 417...\n",
      "Generating episode 418...\n",
      "Generating episode 419...\n",
      "Generating episode 420...\n",
      "Generating episode 421...\n",
      "Generating episode 422...\n",
      "Generating episode 423...\n",
      "Generating episode 424...\n",
      "Generating episode 425...\n",
      "Generating episode 426...\n",
      "Generating episode 427...\n",
      "Generating episode 428...\n",
      "Generating episode 429...\n",
      "Generating episode 430...\n",
      "Generating episode 431...\n",
      "Generating episode 432...\n",
      "Generating episode 433...\n",
      "Generating episode 434...\n",
      "Generating episode 435...\n",
      "Generating episode 436...\n",
      "Generating episode 437...\n",
      "Generating episode 438...\n",
      "Generating episode 439...\n",
      "Generating episode 440...\n",
      "Generating episode 441...\n",
      "Generating episode 442...\n",
      "Generating episode 443...\n",
      "Generating episode 444...\n",
      "Generating episode 445...\n",
      "Generating episode 446...\n",
      "Generating episode 447...\n",
      "Generating episode 448...\n",
      "Generating episode 449...\n",
      "Generating episode 450...\n",
      "Generating episode 451...\n",
      "Generating episode 452...\n",
      "Generating episode 453...\n",
      "Generating episode 454...\n",
      "Generating episode 455...\n",
      "Generating episode 456...\n",
      "Generating episode 457...\n",
      "Generating episode 458...\n",
      "Generating episode 459...\n",
      "Generating episode 460...\n",
      "Generating episode 461...\n",
      "Generating episode 462...\n",
      "Generating episode 463...\n",
      "Generating episode 464...\n",
      "Generating episode 465...\n",
      "Generating episode 466...\n",
      "Generating episode 467...\n",
      "Generating episode 468...\n",
      "Generating episode 469...\n",
      "Generating episode 470...\n",
      "Generating episode 471...\n",
      "Generating episode 472...\n",
      "Generating episode 473...\n",
      "Generating episode 474...\n",
      "Generating episode 475...\n",
      "Generating episode 476...\n",
      "Generating episode 477...\n",
      "Generating episode 478...\n",
      "Generating episode 479...\n",
      "Generating episode 480...\n",
      "Generating episode 481...\n",
      "Generating episode 482...\n",
      "Generating episode 483...\n",
      "Generating episode 484...\n",
      "Generating episode 485...\n",
      "Generating episode 486...\n",
      "Generating episode 487...\n",
      "Generating episode 488...\n",
      "Generating episode 489...\n",
      "Generating episode 490...\n",
      "Generating episode 491...\n",
      "Generating episode 492...\n",
      "Generating episode 493...\n",
      "Generating episode 494...\n",
      "Generating episode 495...\n",
      "Generating episode 496...\n",
      "Generating episode 497...\n",
      "Generating episode 498...\n",
      "Generating episode 499...\n",
      "Generating episode 500...\n",
      "Generating episode 501...\n",
      "Generating episode 502...\n",
      "Generating episode 503...\n",
      "Generating episode 504...\n",
      "Generating episode 505...\n",
      "Generating episode 506...\n",
      "Generating episode 507...\n",
      "Generating episode 508...\n",
      "Generating episode 509...\n",
      "Generating episode 510...\n",
      "Generating episode 511...\n",
      "Generating episode 512...\n",
      "Generating episode 513...\n",
      "Generating episode 514...\n",
      "Generating episode 515...\n",
      "Generating episode 516...\n",
      "Generating episode 517...\n",
      "Generating episode 518...\n",
      "Generating episode 519...\n",
      "Generating episode 520...\n",
      "Generating episode 521...\n",
      "Generating episode 522...\n",
      "Generating episode 523...\n",
      "Generating episode 524...\n",
      "Generating episode 525...\n",
      "Generating episode 526...\n",
      "Generating episode 527...\n",
      "Generating episode 528...\n",
      "Generating episode 529...\n",
      "Generating episode 530...\n",
      "Generating episode 531...\n",
      "Generating episode 532...\n",
      "Generating episode 533...\n",
      "Generating episode 534...\n",
      "Generating episode 535...\n",
      "Generating episode 536...\n",
      "Generating episode 537...\n",
      "Generating episode 538...\n",
      "Generating episode 539...\n",
      "Generating episode 540...\n",
      "Generating episode 541...\n",
      "Generating episode 542...\n",
      "Generating episode 543...\n",
      "Generating episode 544...\n",
      "Generating episode 545...\n",
      "Generating episode 546...\n",
      "Generating episode 547...\n",
      "Generating episode 548...\n",
      "Generating episode 549...\n",
      "Generating episode 550...\n",
      "Generating episode 551...\n",
      "Generating episode 552...\n",
      "Generating episode 553...\n",
      "Generating episode 554...\n",
      "Generating episode 555...\n",
      "Generating episode 556...\n",
      "Generating episode 557...\n",
      "Generating episode 558...\n",
      "Generating episode 559...\n",
      "Generating episode 560...\n",
      "Generating episode 561...\n",
      "Generating episode 562...\n",
      "Generating episode 563...\n",
      "Generating episode 564...\n",
      "Generating episode 565...\n",
      "Generating episode 566...\n",
      "Generating episode 567...\n",
      "Generating episode 568...\n",
      "Generating episode 569...\n",
      "Generating episode 570...\n",
      "Generating episode 571...\n",
      "Generating episode 572...\n",
      "Generating episode 573...\n",
      "Generating episode 574...\n",
      "Generating episode 575...\n",
      "Generating episode 576...\n",
      "Generating episode 577...\n",
      "Generating episode 578...\n",
      "Generating episode 579...\n",
      "Generating episode 580...\n",
      "Generating episode 581...\n",
      "Generating episode 582...\n",
      "Generating episode 583...\n",
      "Generating episode 584...\n",
      "Generating episode 585...\n",
      "Generating episode 586...\n",
      "Generating episode 587...\n",
      "Generating episode 588...\n",
      "Generating episode 589...\n",
      "Generating episode 590...\n",
      "Generating episode 591...\n",
      "Generating episode 592...\n",
      "Generating episode 593...\n",
      "Generating episode 594...\n",
      "Generating episode 595...\n",
      "Generating episode 596...\n",
      "Generating episode 597...\n",
      "Generating episode 598...\n",
      "Generating episode 599...\n",
      "Generating episode 600...\n",
      "Generating episode 601...\n",
      "Generating episode 602...\n",
      "Generating episode 603...\n",
      "Generating episode 604...\n",
      "Generating episode 605...\n",
      "Generating episode 606...\n",
      "Generating episode 607...\n",
      "Generating episode 608...\n",
      "Generating episode 609...\n",
      "Generating episode 610...\n",
      "Generating episode 611...\n",
      "Generating episode 612...\n",
      "Generating episode 613...\n",
      "Generating episode 614...\n",
      "Generating episode 615...\n",
      "Generating episode 616...\n",
      "Generating episode 617...\n",
      "Generating episode 618...\n",
      "Generating episode 619...\n",
      "Generating episode 620...\n",
      "Generating episode 621...\n",
      "Generating episode 622...\n",
      "Generating episode 623...\n",
      "Generating episode 624...\n",
      "Generating episode 625...\n",
      "Generating episode 626...\n",
      "Generating episode 627...\n",
      "Generating episode 628...\n",
      "Generating episode 629...\n",
      "Generating episode 630...\n",
      "Generating episode 631...\n",
      "Generating episode 632...\n",
      "Generating episode 633...\n",
      "Generating episode 634...\n",
      "Generating episode 635...\n",
      "Generating episode 636...\n",
      "Generating episode 637...\n",
      "Generating episode 638...\n",
      "Generating episode 639...\n",
      "Generating episode 640...\n",
      "Generating episode 641...\n",
      "Generating episode 642...\n",
      "Generating episode 643...\n",
      "Generating episode 644...\n",
      "Generating episode 645...\n",
      "Generating episode 646...\n",
      "Generating episode 647...\n",
      "Generating episode 648...\n",
      "Generating episode 649...\n",
      "Generating episode 650...\n",
      "Generating episode 651...\n",
      "Generating episode 652...\n",
      "Generating episode 653...\n",
      "Generating episode 654...\n",
      "Generating episode 655...\n",
      "Generating episode 656...\n",
      "Generating episode 657...\n",
      "Generating episode 658...\n",
      "Generating episode 659...\n",
      "Generating episode 660...\n",
      "Generating episode 661...\n",
      "Generating episode 662...\n",
      "Generating episode 663...\n",
      "Generating episode 664...\n",
      "Generating episode 665...\n",
      "Generating episode 666...\n",
      "Generating episode 667...\n",
      "Generating episode 668...\n",
      "Generating episode 669...\n",
      "Generating episode 670...\n",
      "Generating episode 671...\n",
      "Generating episode 672...\n",
      "Generating episode 673...\n",
      "Generating episode 674...\n",
      "Generating episode 675...\n",
      "Generating episode 676...\n",
      "Generating episode 677...\n",
      "Generating episode 678...\n",
      "Generating episode 679...\n",
      "Generating episode 680...\n",
      "Generating episode 681...\n",
      "Generating episode 682...\n",
      "Generating episode 683...\n",
      "Generating episode 684...\n",
      "Generating episode 685...\n",
      "Generating episode 686...\n",
      "Generating episode 687...\n",
      "Generating episode 688...\n",
      "Generating episode 689...\n",
      "Generating episode 690...\n",
      "Generating episode 691...\n",
      "Generating episode 692...\n",
      "Generating episode 693...\n",
      "Generating episode 694...\n",
      "Generating episode 695...\n",
      "Generating episode 696...\n",
      "Generating episode 697...\n",
      "Generating episode 698...\n",
      "Generating episode 699...\n",
      "Generating episode 700...\n",
      "Generating episode 701...\n",
      "Generating episode 702...\n",
      "Generating episode 703...\n",
      "Generating episode 704...\n",
      "Generating episode 705...\n",
      "Generating episode 706...\n",
      "Generating episode 707...\n",
      "Generating episode 708...\n",
      "Generating episode 709...\n",
      "Generating episode 710...\n",
      "Generating episode 711...\n",
      "Generating episode 712...\n",
      "Generating episode 713...\n",
      "Generating episode 714...\n",
      "Generating episode 715...\n",
      "Generating episode 716...\n",
      "Generating episode 717...\n",
      "Generating episode 718...\n",
      "Generating episode 719...\n",
      "Generating episode 720...\n",
      "Generating episode 721...\n",
      "Generating episode 722...\n",
      "Generating episode 723...\n",
      "Generating episode 724...\n",
      "Generating episode 725...\n",
      "Generating episode 726...\n",
      "Generating episode 727...\n",
      "Generating episode 728...\n",
      "Generating episode 729...\n",
      "Generating episode 730...\n",
      "Generating episode 731...\n",
      "Generating episode 732...\n",
      "Generating episode 733...\n",
      "Generating episode 734...\n",
      "Generating episode 735...\n",
      "Generating episode 736...\n",
      "Generating episode 737...\n",
      "Generating episode 738...\n",
      "Generating episode 739...\n",
      "Generating episode 740...\n",
      "Generating episode 741...\n",
      "Generating episode 742...\n",
      "Generating episode 743...\n",
      "Generating episode 744...\n",
      "Generating episode 745...\n",
      "Generating episode 746...\n",
      "Generating episode 747...\n",
      "Generating episode 748...\n",
      "Generating episode 749...\n",
      "Generating episode 750...\n",
      "Generating episode 751...\n",
      "Generating episode 752...\n",
      "Generating episode 753...\n",
      "Generating episode 754...\n",
      "Generating episode 755...\n",
      "Generating episode 756...\n",
      "Generating episode 757...\n",
      "Generating episode 758...\n",
      "Generating episode 759...\n",
      "Generating episode 760...\n",
      "Generating episode 761...\n",
      "Generating episode 762...\n",
      "Generating episode 763...\n",
      "Generating episode 764...\n",
      "Generating episode 765...\n",
      "Generating episode 766...\n",
      "Generating episode 767...\n",
      "Generating episode 768...\n",
      "Generating episode 769...\n",
      "Generating episode 770...\n",
      "Generating episode 771...\n",
      "Generating episode 772...\n",
      "Generating episode 773...\n",
      "Generating episode 774...\n",
      "Generating episode 775...\n",
      "Generating episode 776...\n",
      "Generating episode 777...\n",
      "Generating episode 778...\n",
      "Generating episode 779...\n",
      "Generating episode 780...\n",
      "Generating episode 781...\n",
      "Generating episode 782...\n",
      "Generating episode 783...\n",
      "Generating episode 784...\n",
      "Generating episode 785...\n",
      "Generating episode 786...\n",
      "Generating episode 787...\n",
      "Generating episode 788...\n",
      "Generating episode 789...\n",
      "Generating episode 790...\n",
      "Generating episode 791...\n",
      "Generating episode 792...\n",
      "Generating episode 793...\n",
      "Generating episode 794...\n",
      "Generating episode 795...\n",
      "Generating episode 796...\n",
      "Generating episode 797...\n",
      "Generating episode 798...\n",
      "Generating episode 799...\n",
      "Generating episode 800...\n",
      "Generating episode 801...\n",
      "Generating episode 802...\n",
      "Generating episode 803...\n",
      "Generating episode 804...\n",
      "Generating episode 805...\n",
      "Generating episode 806...\n",
      "Generating episode 807...\n",
      "Generating episode 808...\n",
      "Generating episode 809...\n",
      "Generating episode 810...\n",
      "Generating episode 811...\n",
      "Generating episode 812...\n",
      "Generating episode 813...\n",
      "Generating episode 814...\n",
      "Generating episode 815...\n",
      "Generating episode 816...\n",
      "Generating episode 817...\n",
      "Generating episode 818...\n",
      "Generating episode 819...\n",
      "Generating episode 820...\n",
      "Generating episode 821...\n",
      "Generating episode 822...\n",
      "Generating episode 823...\n",
      "Generating episode 824...\n",
      "Generating episode 825...\n",
      "Generating episode 826...\n",
      "Generating episode 827...\n",
      "Generating episode 828...\n",
      "Generating episode 829...\n",
      "Generating episode 830...\n",
      "Generating episode 831...\n",
      "Generating episode 832...\n",
      "Generating episode 833...\n",
      "Generating episode 834...\n",
      "Generating episode 835...\n",
      "Generating episode 836...\n",
      "Generating episode 837...\n",
      "Generating episode 838...\n",
      "Generating episode 839...\n",
      "Generating episode 840...\n",
      "Generating episode 841...\n",
      "Generating episode 842...\n",
      "Generating episode 843...\n",
      "Generating episode 844...\n",
      "Generating episode 845...\n",
      "Generating episode 846...\n",
      "Generating episode 847...\n",
      "Generating episode 848...\n",
      "Generating episode 849...\n",
      "Generating episode 850...\n",
      "Generating episode 851...\n",
      "Generating episode 852...\n",
      "Generating episode 853...\n",
      "Generating episode 854...\n",
      "Generating episode 855...\n",
      "Generating episode 856...\n",
      "Generating episode 857...\n",
      "Generating episode 858...\n",
      "Generating episode 859...\n",
      "Generating episode 860...\n",
      "Generating episode 861...\n",
      "Generating episode 862...\n",
      "Generating episode 863...\n",
      "Generating episode 864...\n",
      "Generating episode 865...\n",
      "Generating episode 866...\n",
      "Generating episode 867...\n",
      "Generating episode 868...\n",
      "Generating episode 869...\n",
      "Generating episode 870...\n",
      "Generating episode 871...\n",
      "Generating episode 872...\n",
      "Generating episode 873...\n",
      "Generating episode 874...\n",
      "Generating episode 875...\n",
      "Generating episode 876...\n",
      "Generating episode 877...\n",
      "Generating episode 878...\n",
      "Generating episode 879...\n",
      "Generating episode 880...\n",
      "Generating episode 881...\n",
      "Generating episode 882...\n",
      "Generating episode 883...\n",
      "Generating episode 884...\n",
      "Generating episode 885...\n",
      "Generating episode 886...\n",
      "Generating episode 887...\n",
      "Generating episode 888...\n",
      "Generating episode 889...\n",
      "Generating episode 890...\n",
      "Generating episode 891...\n",
      "Generating episode 892...\n",
      "Generating episode 893...\n",
      "Generating episode 894...\n",
      "Generating episode 895...\n",
      "Generating episode 896...\n",
      "Generating episode 897...\n",
      "Generating episode 898...\n",
      "Generating episode 899...\n",
      "Generating episode 900...\n",
      "Generating episode 901...\n",
      "Generating episode 902...\n",
      "Generating episode 903...\n",
      "Generating episode 904...\n",
      "Generating episode 905...\n",
      "Generating episode 906...\n",
      "Generating episode 907...\n",
      "Generating episode 908...\n",
      "Generating episode 909...\n",
      "Generating episode 910...\n",
      "Generating episode 911...\n",
      "Generating episode 912...\n",
      "Generating episode 913...\n",
      "Generating episode 914...\n",
      "Generating episode 915...\n",
      "Generating episode 916...\n",
      "Generating episode 917...\n",
      "Generating episode 918...\n",
      "Generating episode 919...\n",
      "Generating episode 920...\n",
      "Generating episode 921...\n",
      "Generating episode 922...\n",
      "Generating episode 923...\n",
      "Generating episode 924...\n",
      "Generating episode 925...\n",
      "Generating episode 926...\n",
      "Generating episode 927...\n",
      "Generating episode 928...\n",
      "Generating episode 929...\n",
      "Generating episode 930...\n",
      "Generating episode 931...\n",
      "Generating episode 932...\n",
      "Generating episode 933...\n",
      "Generating episode 934...\n",
      "Generating episode 935...\n",
      "Generating episode 936...\n",
      "Generating episode 937...\n",
      "Generating episode 938...\n",
      "Generating episode 939...\n",
      "Generating episode 940...\n",
      "Generating episode 941...\n",
      "Generating episode 942...\n",
      "Generating episode 943...\n",
      "Generating episode 944...\n",
      "Generating episode 945...\n",
      "Generating episode 946...\n",
      "Generating episode 947...\n",
      "Generating episode 948...\n",
      "Generating episode 949...\n",
      "Generating episode 950...\n",
      "Generating episode 951...\n",
      "Generating episode 952...\n",
      "Generating episode 953...\n",
      "Generating episode 954...\n",
      "Generating episode 955...\n",
      "Generating episode 956...\n",
      "Generating episode 957...\n",
      "Generating episode 958...\n",
      "Generating episode 959...\n",
      "Generating episode 960...\n",
      "Generating episode 961...\n",
      "Generating episode 962...\n",
      "Generating episode 963...\n",
      "Generating episode 964...\n",
      "Generating episode 965...\n",
      "Generating episode 966...\n",
      "Generating episode 967...\n",
      "Generating episode 968...\n",
      "Generating episode 969...\n",
      "Generating episode 970...\n",
      "Generating episode 971...\n",
      "Generating episode 972...\n",
      "Generating episode 973...\n",
      "Generating episode 974...\n",
      "Generating episode 975...\n",
      "Generating episode 976...\n",
      "Generating episode 977...\n",
      "Generating episode 978...\n",
      "Generating episode 979...\n",
      "Generating episode 980...\n",
      "Generating episode 981...\n",
      "Generating episode 982...\n",
      "Generating episode 983...\n",
      "Generating episode 984...\n",
      "Generating episode 985...\n",
      "Generating episode 986...\n",
      "Generating episode 987...\n",
      "Generating episode 988...\n",
      "Generating episode 989...\n",
      "Generating episode 990...\n",
      "Generating episode 991...\n",
      "Generating episode 992...\n",
      "Generating episode 993...\n",
      "Generating episode 994...\n",
      "Generating episode 995...\n",
      "Generating episode 996...\n",
      "Generating episode 997...\n",
      "Generating episode 998...\n",
      "Generating episode 999...\n",
      "Generating episode 1000...\n"
     ]
    }
   ],
   "source": [
    "env = HoverLunarLander(gym.make(\"LunarLanderContinuous-v2\", render_mode=None))\n",
    "actor.eval()\n",
    "\n",
    "N = 1000\n",
    "\n",
    "# Dataset container\n",
    "dataset = {\"states\": [], \"actions\": [], \"rewards\": [], \"next_states\": []}\n",
    "\n",
    "# Generate N episodes\n",
    "for episode in range(N):\n",
    "    state = temp_env.reset()[0]  # Reset the environment\n",
    "    episode_states, episode_actions, episode_rewards, episode_next_states = [], [], [], []\n",
    "    done = False\n",
    "    counter = 0\n",
    "    print(f\"Generating episode {episode + 1}...\")\n",
    "    while not done and counter < 200:\n",
    "        # Convert state to a PyTorch tensor\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Get action from the actor\n",
    "        action = actor(state_tensor).detach().numpy().squeeze()\n",
    "\n",
    "        # Take a step in the environment\n",
    "        next_state, reward, done, _, _ = temp_env.step(action)\n",
    "\n",
    "        # Append step data\n",
    "        episode_states.append(state)\n",
    "        episode_actions.append(action)\n",
    "        episode_rewards.append(reward)\n",
    "        episode_next_states.append(next_state)\n",
    "\n",
    "        # Move to next state\n",
    "        state = next_state\n",
    "        counter += 1\n",
    "\n",
    "    # Store the episode data\n",
    "    dataset[\"states\"].append(torch.tensor(episode_states, dtype=torch.float32))\n",
    "    dataset[\"actions\"].append(torch.tensor(episode_actions, dtype=torch.float32))\n",
    "    dataset[\"rewards\"].append(torch.tensor(episode_rewards, dtype=torch.float32))\n",
    "    dataset[\"next_states\"].append(torch.tensor(episode_next_states, dtype=torch.float32))\n",
    "# Save the dataset as PyTorch tensors\n",
    "torch.save(dataset, \"lunarlander_custom_reward_trained_dataset.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Render Gif Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloaded Actor network loaded.\n",
      "Actor target network initialized with preloaded Actor weights.\n",
      "New Critic network initialized.\n",
      "Critic target network initialized with Critic weights.\n",
      "Rendered GIF saved as rendered_episode.gif\n"
     ]
    }
   ],
   "source": [
    "def render_episode_gif(actor, state_dim, action_dim, max_action, device=None, render_delay=0.02):\n",
    "    \"\"\"\n",
    "    Renders a single episode of the agent interacting with the HoverLunarLander environment and saves it as a GIF.\n",
    "    \n",
    "    Args:\n",
    "        actor (nn.Module): Trained Actor network.\n",
    "        state_dim (int): Dimension of the state space.\n",
    "        action_dim (int): Dimension of the action space.\n",
    "        max_action (float): Maximum action value.\n",
    "        device (torch.device, optional): Device to run the network on. If None, defaults to CUDA if available.\n",
    "        render_delay (float, optional): Delay between frames in seconds. Useful to control rendering speed. Defaults to 0.02.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize device\n",
    "    if device is None:\n",
    "        device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize environment with custom reward and render_mode='rgb_array'\n",
    "    env = HoverLunarLander(gym.make(\"LunarLanderContinuous-v2\", render_mode='rgb_array'))\n",
    "    \n",
    "    # Initialize agent with only the actor\n",
    "    agent = DDPGAgent(state_dim, action_dim, max_action, device, actor=actor, critic=None)\n",
    "    \n",
    "    # Initialize environment and get initial state\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    step_count = 0\n",
    "    \n",
    "    images = []  # To store frames\n",
    "    \n",
    "    while not done and step_count < 250:\n",
    "        action = agent.select_action(state)\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        frame = env.render()  # Removed mode='rgb_array'\n",
    "        images.append(frame)\n",
    "        step_count += 1\n",
    "        \n",
    "        # Optional: Add a small delay to make rendering visible (not needed for GIF)\n",
    "        # import time\n",
    "        # time.sleep(render_delay)\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    # Save images as gif, loop=0 means infinite loop\n",
    "    gif_path = 'rendered_episode.gif'\n",
    "    imageio.mimsave(gif_path, images, fps=30, loop=0)\n",
    "    print(f\"Rendered GIF saved as {gif_path}\")\n",
    "#load actor\n",
    "\n",
    "render_episode_gif(actor, state_dim=8, action_dim=2, max_action=1.0, device=None, render_delay=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
