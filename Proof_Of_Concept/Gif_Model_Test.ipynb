{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = torch.linspace(-5 * np.pi, 5 * np.pi, 1000).unsqueeze(1)\n",
    "all_next_values = torch.sin(all_values)\n",
    "\n",
    "# Create pairs (x, y)\n",
    "data = torch.stack((all_values, all_next_values), dim=1)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled_indices = torch.randperm(len(data))\n",
    "shuffled_data = data[shuffled_indices]\n",
    "\n",
    "# Determine split indices\n",
    "split_index = int(0.8 * len(shuffled_data))  # 80% for training\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data = shuffled_data[:split_index]\n",
    "test_data = shuffled_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR(nn.Module):\n",
    "    def __init__(self, enc_dim):\n",
    "        super(LQR, self).__init__()\n",
    "        self.A = torch.nn.Parameter(torch.randn(enc_dim, enc_dim))\n",
    "       \n",
    "        self.state_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, enc_dim//2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(enc_dim//2, enc_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(enc_dim, enc_dim),\n",
    "        )\n",
    "\n",
    "        self.state_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(enc_dim, enc_dim//2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(enc_dim//2, 1)\n",
    "        )\n",
    "    def forward (self,x):\n",
    "        xx = self.state_encoder(x)\n",
    "        x_prime_prediction = self.A @ xx \n",
    "        return self.state_decoder(x_prime_prediction), x_prime_prediction, xx, #reward.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "super_values = torch.linspace(-10 * np.pi, 10 * np.pi, 1000).unsqueeze(1)\n",
    "all_next_super_values = torch.sin(super_values)\n",
    "super_data = torch.cat((super_values, all_next_super_values), dim=1)\n",
    "\n",
    "# Split data into ranges\n",
    "range_1_mask = (super_values.squeeze() >= -5 * np.pi) & (super_values.squeeze() <= 5 * np.pi)\n",
    "range_2_mask = (super_values.squeeze() > 5 * np.pi) | (super_values.squeeze() < -5 * np.pi)\n",
    "\n",
    "range_1_values = super_values[range_1_mask]\n",
    "range_1_actual = all_next_super_values[range_1_mask]\n",
    "range_2_values = super_values[range_2_mask]\n",
    "range_2_actual = all_next_super_values[range_2_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_performance(model,epoch,folder_name):\n",
    "    test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in super_data:\n",
    "            lqr_x_prime, x_prime_expanded, xx = model(x.unsqueeze(0))\n",
    "            test_predictions.append(lqr_x_prime)\n",
    "    test_predictions = torch.tensor(test_predictions)\n",
    "\n",
    "    # Scatter plot\n",
    "    plt.scatter(\n",
    "        range_1_values, \n",
    "        test_predictions[range_1_mask], \n",
    "        c='r', alpha=0.5, label=\"Predicted (Training Range)\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        range_1_values, \n",
    "        range_1_actual, \n",
    "        c='b', alpha=0.5, label=\"Actual (Training Range)\"\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        range_2_values, \n",
    "        test_predictions[range_2_mask], \n",
    "        c='orange', alpha=0.5, label=\"Predicted (Unseen Range)\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        range_2_values, \n",
    "        range_2_actual, \n",
    "        c='green', alpha=0.5, label=\"Actual (Unseen Range)\"\n",
    "    )\n",
    "    #make x axis in terms of pi\n",
    "\n",
    "\n",
    "    # Add legend and labels, legend should be outside the plot\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(f'{folder_name}, Encoder Dimension: {64} Epoch: {epoch}')\n",
    "    plt.xlabel('Neg 10 pi to 10 pi')\n",
    "    plt.ylabel('Sin(Pi)')\n",
    "    plt.ylim(-1.2, 2)\n",
    "    plt.xlim(-10 * np.pi, 10 * np.pi)\n",
    "    #plt.show()\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    plt.savefig(f'{folder_name}/epoch_{epoch}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test are lists of tuples of (x, u, y, r)\n",
    "def train_model(model,optimizer,epochs=1):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for i in range(epochs):\n",
    "        total_state_loss = 0\n",
    "        total_reward_loss = 0\n",
    "        for x, y in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            lqr_x_prime, x_prime_expanded, xx = model(x)\n",
    "            #reward_loss = criterion(reward, r)\n",
    "            lqr_pred_loss = criterion(lqr_x_prime, y)\n",
    "            decoder_loss = criterion(model.state_decoder(xx), x)\n",
    "            encoder_loss = criterion(model.state_encoder(y), x_prime_expanded) \n",
    "            state_loss = lqr_pred_loss  + decoder_loss + encoder_loss\n",
    "            loss = state_loss #+ reward_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_state_loss += state_loss.item()\n",
    "            total_reward_loss += 0#reward_loss.item()\n",
    "        # if i % 10 == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         total_test_state_loss = 0\n",
    "        #         total_test_reward_loss = 0\n",
    "        #         for x, y, in test_data:\n",
    "        #             lqr_x_prime, x_prime_expanded, xx, = model(x)\n",
    "        #             #reward_loss = criterion(reward, r)\n",
    "        #             lqr_pred_loss = criterion(lqr_x_prime, y)\n",
    "        #             decoder_loss = criterion(model.state_decoder(xx), x)\n",
    "        #             encoder_loss = criterion(model.state_encoder(y), x_prime_expanded) \n",
    "        #             state_loss = lqr_pred_loss  + decoder_loss + encoder_loss\n",
    "        #             total_test_state_loss += state_loss.item()\n",
    "        #             total_test_reward_loss += 0#reward_loss.item()\n",
    "        #         print(f\"Epoch {i}, Train State Loss: {total_state_loss}, Train Reward Loss: {total_reward_loss}, Test State Loss: {total_test_state_loss}, Test Reward Loss: {total_test_reward_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(folder_name):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder_name)):\n",
    "        images.append(imageio.imread(f'{folder_name}/{filename}'))\n",
    "    #make dir, gifs\n",
    "    os.makedirs('gifs', exist_ok=True)\n",
    "    imageio.mimsave(f'gifs/{folder_name}.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikef\\AppData\\Local\\Temp\\ipykernel_16820\\2366880764.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f'{folder_name}/{filename}'))\n"
     ]
    }
   ],
   "source": [
    "model = LQR(64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "file_name = \"Normal_Model\"\n",
    "for epoch in range(100):\n",
    "    train_model(model,optimizer,epochs=1)\n",
    "    visualize_model_performance(model,epoch,file_name)\n",
    "make_gif(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikef\\AppData\\Local\\Temp\\ipykernel_16820\\2557204798.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f'{folder_name}/{filename}'))\n"
     ]
    }
   ],
   "source": [
    "model = LQR(64)\n",
    "#freeze encoder and decoder\n",
    "for param in model.state_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.state_decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "file_name = \"Frozen Encoder and Decoder\"\n",
    "for epoch in range(100):\n",
    "    train_model(model,optimizer,epochs=1)\n",
    "    visualize_model_performance(model,epoch,file_name)\n",
    "make_gif(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikef\\AppData\\Local\\Temp\\ipykernel_16820\\2366880764.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f'{folder_name}/{filename}'))\n"
     ]
    }
   ],
   "source": [
    "model = LQR(64)\n",
    "#freeze A\n",
    "model.A.requires_grad = False\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "file_name = \"Frozen A\"\n",
    "for epoch in range(100):\n",
    "    train_model(model,optimizer,epochs=1)\n",
    "    visualize_model_performance(model,epoch,file_name)\n",
    "make_gif(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrozen All\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     visualize_model_performance(model,epoch,file_name)\n\u001b[0;32m     15\u001b[0m make_gif(file_name)\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m state_loss \u001b[38;5;241m=\u001b[39m lqr_pred_loss  \u001b[38;5;241m+\u001b[39m decoder_loss \u001b[38;5;241m+\u001b[39m encoder_loss\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m state_loss \u001b[38;5;66;03m#+ reward_loss\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m total_state_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m state_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\mikef\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mikef\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mikef\\anaconda3\\envs\\gym\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model = LQR(64)\n",
    "#freeze All\n",
    "model.A.requires_grad = False\n",
    "model.state_encoder.requires_grad = False\n",
    "model.state_decoder.requires_grad = False\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "file_name = \"Frozen All\"\n",
    "for epoch in range(100):\n",
    "    train_model(model,optimizer,epochs=1)\n",
    "    visualize_model_performance(model,epoch,file_name)\n",
    "make_gif(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
